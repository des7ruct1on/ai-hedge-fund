"""
–í–µ–±-–≤–µ—Ä—Å–∏—è workflow —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
"""
import json
import logging
from datetime import datetime
from zoneinfo import ZoneInfo
from dateutil.relativedelta import relativedelta
import pandas as pd
from langgraph.graph import StateGraph, START, END
from models import State, AgentOpinion, AggregatedDecision, RiskAssessment
from enums import StageEnum
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import ToolNode
from langgraph.graph.message import add_messages
from investor_agents import InvestorAgentRoom
from utils import aggregate_agent_opinions
from prompts import RISK_MANAGER_PROMPT, PORTFOLIO_AGENT_PROMPT
from langgraph.types import Command
from moex_parser import MoexISS
from risk_tools import compute_risk_features

logging.basicConfig(
    filename='web_workflow.log',
    level=logging.INFO,
    format='%(asctime)s %(levelname)s %(message)s'
)

web_analysis_results = {
    "agent_opinions": [],
    "aggregated_decisions": [],
    "risk_assessments": [],
    "final_recommendations": ""
}

moex_equity = MoexISS(engine="stock", market="shares")  # –∞–∫—Ü–∏–∏
moex_index  = MoexISS(engine="stock", market="index")   # –∏–Ω–¥–µ–∫—Å—ã (IMOEX, RTSI, IMOEXTR –∏ —Ç.–¥.)


class WebGraph(StateGraph):
    def __init__(self, llm):
        self.llm = llm
        self.memory = MemorySaver()
        self.agent_room = InvestorAgentRoom(llm)

    def get_graph(self):
        graph = StateGraph(State)

        graph.add_node(StageEnum.USER_DATA_NODE, self.user_data_node)
        graph.add_node(StageEnum.NEWS_DATA_NODE, self.news_data_node)
        graph.add_node(StageEnum.DISCUSSION_NODE, self.discussion_node)
        graph.add_node(StageEnum.RISK_NODE, self.risk_node)
        graph.add_node(StageEnum.FINALIZER_NODE, self.finalizer_node)

        graph.add_edge(START, StageEnum.DISCUSSION_NODE)

        graph.add_conditional_edges(
            StageEnum.DISCUSSION_NODE,
            lambda x: x["stage"],
            {
                StageEnum.RISK_NODE: StageEnum.RISK_NODE,
                StageEnum.USER_DATA_NODE: StageEnum.USER_DATA_NODE,
                StageEnum.NEWS_DATA_NODE: StageEnum.NEWS_DATA_NODE,
            }
        )
        graph.add_edge(StageEnum.RISK_NODE, StageEnum.FINALIZER_NODE)
        graph.add_edge(StageEnum.FINALIZER_NODE, END)

        return graph.compile(checkpointer=self.memory)

    def user_data_node(self, state: State) -> State:
        logging.info("User data node")
        try:
            with open("user_portfolio.json", "r", encoding="utf-8") as f:
                user_data = json.load(f)
            
            logging.info("User data loaded")
            return Command(
                goto=StageEnum.DISCUSSION_NODE,
                update={
                    "user_data": user_data,
                    "stage": StageEnum.DISCUSSION_NODE
                }
            )

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è: {e}")
            return Command(
                goto=END,
                update={
                    "stage": END,
                    "message_to_user": f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è: {e}"
                }
            )

    def news_data_node(self, state: State) -> State:
        logging.info("News data node")
        try:
            with open("sample_news.json", "r", encoding="utf-8") as f:
                news_data = json.load(f)
            
            logging.info("News data loaded")
            return Command(
                goto=StageEnum.DISCUSSION_NODE,
                update={
                    "news_data": news_data,
                    "stage": StageEnum.DISCUSSION_NODE
                }
            )

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
            return Command(
                goto=END,
                update={
                    "stage": END,
                    "message_to_user": f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π: {e}"
                }
            )
    
    def discussion_node(self, state: State) -> State:
        logging.info("Discussion node")
        try:
            logging.info("Checking user data")
            if not state.get("user_data"):
                return Command(
                    goto=StageEnum.USER_DATA_NODE,
                    update={
                        "stage": StageEnum.USER_DATA_NODE
                    }
                )

            logging.info("Checking news data")
            if not state.get("news_data"):
                return Command(
                    goto=StageEnum.NEWS_DATA_NODE,
                    update={
                        "stage": StageEnum.NEWS_DATA_NODE
                    }
                )
            
            logging.info("ü§ñ –ê–≥–µ–Ω—Ç—ã –Ω–∞—á–∏–Ω–∞—é—Ç –æ–±—Å—É–∂–¥–µ–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª—è...")
            agent_opinions = self.agent_room.discuss_portfolio(
                state["user_data"], 
                state["news_data"]
            )
            
            logging.info("üîÑ –ê–ì–†–ï–ì–ê–¶–ò–Ø –†–ï–®–ï–ù–ò–ô –ê–ì–ï–ù–¢–û–í")
            logging.info("-" * 40)
            aggregated_decisions = aggregate_agent_opinions(agent_opinions)
            
            logging.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(agent_opinions)} –º–Ω–µ–Ω–∏–π –æ—Ç –∞–≥–µ–Ω—Ç–æ–≤")
            logging.info(f"üìä –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–æ {len(aggregated_decisions)} —Ä–µ—à–µ–Ω–∏–π")
            
            for decision in aggregated_decisions:
                logging.info(
                    f"üìã {decision.ticker}: {decision.final_action} "
                    f"(—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {decision.confidence_score:.1f}, "
                    f"–∫–æ–Ω—Å–µ–Ω—Å—É—Å: {decision.consensus_strength:.1f})"
                )

            web_analysis_results["agent_opinions"] = agent_opinions
            web_analysis_results["aggregated_decisions"] = aggregated_decisions

            return Command(
                goto=StageEnum.RISK_NODE,
                update={
                    "agent_opinions": agent_opinions,
                    "aggregated_decisions": aggregated_decisions,
                    "stage": StageEnum.RISK_NODE
                }
            )

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –≤ –æ–±—Å—É–∂–¥–µ–Ω–∏–∏ –∞–≥–µ–Ω—Ç–æ–≤: {e}")
            return Command(
                goto=END,
                update={
                    "stage": END,
                    "message_to_user": f"–û—à–∏–±–∫–∞ –≤ –æ–±—Å—É–∂–¥–µ–Ω–∏–∏ –∞–≥–µ–Ω—Ç–æ–≤: {e}"
                }
            )
                
    def risk_node(self, state: State) -> State:
        logging.info("Risk node")
        try:
            logging.info("‚ö†Ô∏è –†–∏—Å–∫-–º–µ–Ω–µ–¥–∂–µ—Ä –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–∏—Å–∫–∏...")
            
            risk_assessments = []
            aggregated_decisions = state.get("aggregated_decisions", [])

            start_date, end_date = self.get_range()
            
            for decision in aggregated_decisions:

                risk_features_json = self._build_risk_features_json(decision.ticker, start_date, end_date)

                context = f"""
                –¢–∏–∫–µ—Ä: {decision.ticker}
                –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ: {decision.final_action}
                –£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {decision.confidence_score}
                –°–∏–ª–∞ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞: {decision.consensus_strength}
                
                –ú–Ω–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤:
                """
                
                for opinion in decision.agent_opinions:
                    context += f"- {opinion.agent_name}: {opinion.action} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {opinion.confidence})\n"
                    context += f"  –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: {opinion.reasoning}\n"
                
                full_prompt = (
                f"{RISK_MANAGER_PROMPT}\n\n"
                f"[QUANT_RISK_CONTEXT]\n{risk_features_json}\n\n"
                f"{context}"
                )

                print(full_prompt)
                
                try:
                    response = self.llm.complete(full_prompt, temperature=0.3, max_tokens=500)
                    
                    risk_level = self._extract_risk_level(response)
                    risk_factors = self._extract_risk_factors(response)
                    
                    risk_assessments.append(RiskAssessment(
                        ticker=decision.ticker,
                        risk_level=risk_level,
                        risk_factors=risk_factors,
                        recommendations=response
                    ))
                    
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–∞ –¥–ª—è {decision.ticker}: {e}")
                    risk_assessments.append(RiskAssessment(
                        ticker=decision.ticker,
                        risk_level=5,
                        risk_factors=["–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞"],
                        recommendations="–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"
                    ))
            
            logging.info(f"‚úÖ –û—Ü–µ–Ω–µ–Ω—ã —Ä–∏—Å–∫–∏ –¥–ª—è {len(risk_assessments)} –ø–æ–∑–∏—Ü–∏–π")
            
            for risk in risk_assessments:
                logging.info(f"‚ö†Ô∏è {risk.ticker}: —É—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞ {risk.risk_level}/10")

            web_analysis_results["risk_assessments"] = risk_assessments

            return Command(
                goto=StageEnum.FINALIZER_NODE,
                update={
                    "risk_assessments": risk_assessments,
                    "stage": StageEnum.FINALIZER_NODE
                }
            )

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –≤ –æ—Ü–µ–Ω–∫–µ —Ä–∏—Å–∫–æ–≤: {e}")
            return Command(
                goto=END,
                update={
                    "stage": END,
                    "message_to_user": f"–û—à–∏–±–∫–∞ –≤ –æ—Ü–µ–Ω–∫–µ —Ä–∏—Å–∫–æ–≤: {e}"
                }
            )   
            
    def finalizer_node(self, state: State) -> State:
        logging.info("Finalizer node")
        try:
            logging.info("üìã –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π...")
            
            context = self._build_finalizer_context(state)
            
            
            full_prompt = f"{PORTFOLIO_AGENT_PROMPT}\n\n{context}"
            
            final_recommendations = self.llm.complete(full_prompt, temperature=0.5, max_tokens=2000)
            
            logging.info("‚úÖ –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã")

            web_analysis_results["final_recommendations"] = final_recommendations

            return Command(
                goto=END,
                update={
                    "final_recommendations": final_recommendations,
                    "message_to_user": final_recommendations,
                    "stage": END
                }
            )

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
            return Command(
                goto=END,
                update={
                    "stage": END,
                    "message_to_user": f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}"
                }
            )

    def _extract_risk_level(self, response: str) -> int:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —É—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞ —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–µ—Ä–∞"""
        import re
        risk_match = re.search(r'—Ä–∏—Å–∫[–∞-—è]*\s*[:\-]?\s*(\d+)', response, re.IGNORECASE)
        if risk_match:
            return int(risk_match.group(1))
        return 5 

    def _extract_risk_factors(self, response: str) -> list:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞"""
        factors = []
        lines = response.split('\n')
        for line in lines:
            if any(keyword in line.lower() for keyword in ['—Ä–∏—Å–∫', '–æ–ø–∞—Å–Ω–æ—Å—Ç—å', '—É–≥—Ä–æ–∑–∞']):
                factors.append(line.strip())
        return factors[:3] 
    

    def get_range(self, months_back: int = 1, tz: str = 'Europe/Moscow') -> tuple[str, str]:
        
        today_local = datetime.now(ZoneInfo(tz)).date()
        start_date = (today_local - relativedelta(months=months_back)).isoformat()
        end_date = today_local.isoformat()
        return start_date, end_date
    
    def _bench_close_series(self, bench_secid: str, start: str, end: str) -> pd.Series | None:
        
        c = moex_index.get_candles(bench_secid, start, end, interval=24)
        if c is None or c.empty:
            return None
        s = c[["end", "close"]].copy()
        s["date"] = pd.to_datetime(s["end"]).dt.date
        return s.set_index("date")["close"].astype(float).sort_index()

    def _build_risk_features_json(self, secid: str, start: str, end: str) -> str:
        # –±–∞–∑–æ–≤—ã–π –¥–Ω–µ–≤–Ω–æ–π —Ä—è–¥ –∑–∞–∫—Ä—ã—Ç–∏–π (LEGALCLOSEPRICE/CLOSE)
        px = moex_equity.get_daily_close_series(secid, start, end, board="TQBR")
        # –¥–Ω–µ–≤–Ω—ã–µ —Å–≤–µ—á–∏ (OHLC) ‚Äî –¥–ª—è Parkinson/Garman‚ÄìKlass
        ohlc = moex_equity.get_candles(secid, start, end, interval=24)
        # –±–µ–Ω—á–º–∞—Ä–∫
        bench = self._bench_close_series("IMOEX", start, end)
        rf = compute_risk_features(px_close_daily=px, bench_close_daily=bench, ohlc_daily=ohlc, stl_period=5)
        return json.dumps(rf.__dict__, ensure_ascii=False, default=float)


    def _build_finalizer_context(self, state: State) -> str:
        """–°—Ç—Ä–æ–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
        context = "–ê–ù–ê–õ–ò–ó –ü–û–†–¢–§–ï–õ–Ø\n\n"
        
        user_data = state.get("user_data", {})
        if user_data:
            context += "–¢–µ–∫—É—â–∏–π –ø–æ—Ä—Ç—Ñ–µ–ª—å:\n"
            for ticker, position in user_data.items():
                context += f"- {ticker}: {position.get('quantity', 0)} –∞–∫—Ü–∏–π, "
                context += f"—Å—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞: {position.get('avg_price', 0)} —Ä—É–±.\n"
            context += "\n"
        
        aggregated_decisions = state.get("aggregated_decisions", [])
        if aggregated_decisions:
            context += "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–æ–≤:\n"
            for decision in aggregated_decisions:
                context += f"- {decision.ticker}: {decision.final_action} "
                context += f"(—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {decision.confidence_score:.1f}, "
                context += f"–∫–æ–Ω—Å–µ–Ω—Å—É—Å: {decision.consensus_strength:.1f})\n"
            context += "\n"
        
        risk_assessments = state.get("risk_assessments", [])
        if risk_assessments:
            context += "–û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–æ–≤:\n"
            for risk in risk_assessments:
                context += f"- {risk.ticker}: —É—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞ {risk.risk_level}/10\n"
            context += "\n"
        
        context += "–°—Ñ–æ—Ä–º–∏—Ä—É–π —á–µ—Ç–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é –ø–æ—Ä—Ç—Ñ–µ–ª–µ–º."
        
        return context

def get_web_analysis_results():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
    return web_analysis_results
